{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## template for first exploration \n",
    "Scaling version 1 from 02_feature_engineering\n",
    "used dummies for pure categoricals, kept numericals and scaled them using StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### CHANGE ME \n",
    "Let's plug in the final feature engineering in the following section \n",
    "(left in for having something to work with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root added to path: d:\\Programming\\ai_ds_bootcamp\\ds-ml-project_kickstarters\n"
     ]
    }
   ],
   "source": [
    "#initial imports \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Get the absolute path of the current file/notebook\n",
    "# If using Jupyter, use Path.cwd(). If using a .py script, use Path(__file__).parent\n",
    "curr_dir = Path.cwd()\n",
    "\n",
    "# Calculate the project root (adjust '.parent' count as needed)\n",
    "# If your notebook is in 'project/notebooks/', the root is 1 level up\n",
    "project_root = curr_dir.parent.parent \n",
    "\n",
    "# Add project root to system path so Python can find 'utils'\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project Root added to path: {project_root}\")\n",
    "\n",
    "from utils.feature_engineer_df import build_features \n",
    "\n",
    "#for the scaling and encoding \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#cleanup \n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting feature engineering pipeline\n",
      "INFO:__main__:Loaded 331675 rows\n",
      "INFO:__main__:Computing trending category feature...\n",
      "INFO:__main__:Trending category feature computed: 64,724 projects (22.09%) belong to trending categories\n",
      "INFO:__main__:Final columns before save: ['id', 'main_category', 'deadline', 'launched', 'backers', 'country', 'usd_pledged_real', 'usd_goal_real', 'duration_days', 'target', 'main_category_grouped', 'continent', 'launched_year', 'launched_month', 'deadline_year', 'deadline_month', 'launched_weekday', 'log_usd_goal', 'goal_per_day', 'usd_goal_bins', 'usd_pledged_bins', 'pledged_per_category', 'goal_per_category', 'category_goal_percentile', 'duration_bins', 'backers_per_pledged', 'backer_pledged_bins', 'launch_season', 'deadline_season', 'is_trending_category']\n",
      "INFO:__main__:Saved engineered dataset to D:\\Programming\\ai_ds_bootcamp\\ds-ml-project_kickstarters\\data\\feature\\kickstarter_featured.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering valid dates: 293,019 rows\n"
     ]
    }
   ],
   "source": [
    "#get your data from our utils\n",
    "build_features(\n",
    "    input_path=Path.cwd().resolve().parents[1] / \"data\" / \"cleaned\" / \"kickstarter_cleaned.csv\",\n",
    "    output_path=Path.cwd().resolve().parents[1] / \"data\" / \"feature\" / \"kickstarter_featured.csv\",\n",
    "    raw_path=Path.cwd().resolve().parents[1] / \"data\" / \"raw\" / \"ks-projects-201801.csv\",\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Load Files as DataFrames\n",
    "BASE_DIR = Path.cwd().resolve().parents[1]\n",
    "data_file = BASE_DIR / \"data\" / \"feature\" / \"kickstarter_featured.csv\"\n",
    "\n",
    "filepath = Path(data_file)\n",
    "\n",
    "df = pd.read_csv(filepath, encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Convert launched to datetime for temporal splitting\n",
    "df['launched'] = pd.to_datetime(df['launched'], errors='coerce')\n",
    "df['deadline'] = pd.to_datetime(df['deadline'], errors='coerce')\n",
    "\n",
    "# Filter out rows with invalid dates\n",
    "df = df[df['launched'].notna()].copy()\n",
    "df = df[df['deadline'].notna()].copy()\n",
    "\n",
    "print(f\"After filtering valid dates: {df.shape[0]:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns to \"hard drop\" from feature engineering dataframe\n",
    "# Note: keeping 'launched' temporarily for temporal train/test split\n",
    "columns_to_drop = ['id', #irrelevant\n",
    "                   'main_category', #substituted in a satisfactory way\n",
    "                   'deadline', #created new categories (keeping 'launched' for now)\n",
    "                   'backers', 'usd_pledged_real', 'usd_pledged_bins', 'backers_per_pledged', 'backer_pledged_bins', 'pledged_per_category', #everything to do with \"future information\"\n",
    "                   'launched_year', 'deadline_year', #info about the past and not seasonal\n",
    "                   ]\n",
    "# drop them\n",
    "dfc = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Get dummies for pure categoricals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#season launched, dropping first as it's multicollinear\n",
    "df_sl = pd.get_dummies(df['launch_season'], prefix = 'sl_', drop_first=True, dtype=int)\n",
    "\n",
    "#season deadline, dropping first\n",
    "df_sd = pd.get_dummies(df['deadline_season'], prefix = 'sd_', drop_first=True, dtype=int)\n",
    "\n",
    "#main category_grouped, dropping first\n",
    "df_cat = pd.get_dummies(df['main_category_grouped'], prefix = 'cat_', drop_first=True, dtype=int)\n",
    "\n",
    "#continent, dropping first\n",
    "df_co = pd.get_dummies(df['continent'], prefix = 'co_', drop_first=True, dtype=int)\n",
    "\n",
    "#put everything back together again: \n",
    "dff = pd.concat([dfc, df_sl, df_sd, df_cat, df_co], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's soft-drop everything we just encoded\n",
    "#commented out all the keepers \n",
    "columns_to_softdrop = ['country', #we kept it for comparison\n",
    "                       # 'usd_goal_real', #right now I want to try scaling actual values \n",
    "                       #'duration_days', #I want to scale these and drop the bins instead for now \n",
    "                       # 'target', (obviously)\n",
    "                       'main_category_grouped', 'continent', #after creating dummies, get rid of these!\n",
    "                        'launched_month', 'deadline_month', #because we have season but might want to look closer\n",
    "                        'usd_goal_bins', #using category_goal_percentile (those two are redundant)\n",
    "                        #'goal_per_category', #it's a polynomial feature - not independent but that's probably ok\n",
    "                       'category_goal_percentile', #it's an orinal bin so keeping 'goal per category' instead\n",
    "                       'duration_bins', #want to use actual values instead, using duration_days\n",
    "                       'launch_season', 'deadline_season', #gotten dummies \n",
    "                       #'duration_bins_coded', #dropped the whole encoding code \n",
    "                       ]\n",
    "# keeping the already dummied ones obviously "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['launched', 'usd_goal_real', 'duration_days', 'target',\n",
       "       'launched_weekday', 'log_usd_goal', 'goal_per_day', 'goal_per_category',\n",
       "       'is_trending_category', 'sl__Spring', 'sl__Summer', 'sl__Winter',\n",
       "       'sd__Spring', 'sd__Summer', 'sd__Winter', 'cat__Creative',\n",
       "       'cat__Entertainment', 'cat__Other', 'cat__Tech', 'co__Europe',\n",
       "       'co__North America', 'co__Oceania'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_to_scale = dff.drop(columns=columns_to_softdrop, axis=1)\n",
    "display(df_to_scale.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Scale the remaining numerical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-based split:\n",
      "Train: 2009-04-21 21:02:48 to 2015-11-13 14:38:33\n",
      "Test:  2015-11-13 15:43:30 to 2017-12-29 03:22:32\n",
      "\n",
      "Train size: 205,113 (70.0%)\n",
      "Test size:  87,906 (30.0%)\n",
      "\n",
      "Train success rate: 46.25%\n",
      "Test success rate:  44.47%\n",
      "\n",
      "Final feature matrices:\n",
      "Df before (293019, 22)\n",
      "X_train shape (205113, 20)\n",
      "X_test shape (87906, 20)\n",
      "y_train shape (205113,)\n",
      "y_test shape (87906,)\n"
     ]
    }
   ],
   "source": [
    "# Temporal train/test split (similar to linear regression notebook)\n",
    "# Sort by launch date to ensure temporal ordering\n",
    "df_sorted = df_to_scale.sort_values('launched').copy()\n",
    "\n",
    "# Use 70% earliest projects for training, 30% latest for testing\n",
    "split_idx = int(len(df_sorted) * 0.7)\n",
    "df_train_raw = df_sorted.iloc[:split_idx].copy()\n",
    "df_test_raw = df_sorted.iloc[split_idx:].copy()\n",
    "\n",
    "print(\"Time-based split:\")\n",
    "print(f\"Train: {df_train_raw['launched'].min()} to {df_train_raw['launched'].max()}\")\n",
    "print(f\"Test:  {df_test_raw['launched'].min()} to {df_test_raw['launched'].max()}\")\n",
    "print(f\"\\nTrain size: {len(df_train_raw):,} ({len(df_train_raw)/len(df_sorted):.1%})\")\n",
    "print(f\"Test size:  {len(df_test_raw):,} ({len(df_test_raw)/len(df_sorted):.1%})\")\n",
    "print(f\"\\nTrain success rate: {df_train_raw['target'].mean():.2%}\")\n",
    "print(f\"Test success rate:  {df_test_raw['target'].mean():.2%}\")\n",
    "\n",
    "# Now separate X and y, dropping 'launched' from features\n",
    "X_train = df_train_raw.drop(columns=['target', 'launched'])\n",
    "y_train = df_train_raw['target']\n",
    "X_test = df_test_raw.drop(columns=['target', 'launched'])\n",
    "y_test = df_test_raw['target']\n",
    "\n",
    "print(\"\\nFinal feature matrices:\")\n",
    "print(\"Df before\", df_to_scale.shape)\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the columns to standardise \n",
    "col_scale = ['usd_goal_real',\n",
    "             'duration_days',\n",
    "             'goal_per_category',\n",
    "             ]\n",
    "\n",
    "#instantiate\n",
    "scaler = StandardScaler()\n",
    "#scale - fit on training data only, then transform both train and test\n",
    "X_train_scaled = scaler.fit_transform(X_train[col_scale])\n",
    "X_test_scaled = scaler.transform(X_test[col_scale])  # Use transform, not fit_transform!\n",
    "#make it a df again\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    X_train_scaled,\n",
    "    columns=col_scale,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    X_test_scaled,\n",
    "    columns=col_scale,\n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the original axes again\n",
    "X_train = X_train.drop(col_scale, axis=1)\n",
    "X_test = X_test.drop(col_scale, axis=1)\n",
    "#and check if everything's still in order \n",
    "X_train.index.equals(X_train_scaled.index)\n",
    "X_test.index.equals(X_test_scaled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dff shape (293019, 32)\n",
      "X_train shape (205113, 3)\n",
      "X_test shape (87906, 3)\n",
      "X_train shape after scaling (205113, 20)\n",
      "X_test shape after scaling (87906, 20)\n",
      "train split head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>duration_days</th>\n",
       "      <th>goal_per_category</th>\n",
       "      <th>launched_weekday</th>\n",
       "      <th>log_usd_goal</th>\n",
       "      <th>goal_per_day</th>\n",
       "      <th>is_trending_category</th>\n",
       "      <th>sl__Spring</th>\n",
       "      <th>sl__Summer</th>\n",
       "      <th>sl__Winter</th>\n",
       "      <th>sd__Spring</th>\n",
       "      <th>sd__Summer</th>\n",
       "      <th>sd__Winter</th>\n",
       "      <th>cat__Creative</th>\n",
       "      <th>cat__Entertainment</th>\n",
       "      <th>cat__Other</th>\n",
       "      <th>cat__Tech</th>\n",
       "      <th>co__Europe</th>\n",
       "      <th>co__North America</th>\n",
       "      <th>co__Oceania</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131103</th>\n",
       "      <td>-0.036164</td>\n",
       "      <td>0.428907</td>\n",
       "      <td>-0.570400</td>\n",
       "      <td>1</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>0.172719</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249157</th>\n",
       "      <td>0.054875</td>\n",
       "      <td>4.125306</td>\n",
       "      <td>1.035614</td>\n",
       "      <td>3</td>\n",
       "      <td>11.289794</td>\n",
       "      <td>0.128293</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107410</th>\n",
       "      <td>-0.037294</td>\n",
       "      <td>-1.958351</td>\n",
       "      <td>0.166106</td>\n",
       "      <td>4</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.338280</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251783</th>\n",
       "      <td>-0.037203</td>\n",
       "      <td>3.509240</td>\n",
       "      <td>2.487783</td>\n",
       "      <td>5</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>0.057565</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95067</th>\n",
       "      <td>-0.035127</td>\n",
       "      <td>-0.418185</td>\n",
       "      <td>-0.570400</td>\n",
       "      <td>0</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>0.260349</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        usd_goal_real  duration_days  goal_per_category  launched_weekday   \n",
       "131103      -0.036164       0.428907          -0.570400                 1  \\\n",
       "249157       0.054875       4.125306           1.035614                 3   \n",
       "107410      -0.037294      -1.958351           0.166106                 4   \n",
       "251783      -0.037203       3.509240           2.487783                 5   \n",
       "95067       -0.035127      -0.418185          -0.570400                 0   \n",
       "\n",
       "        log_usd_goal  goal_per_day  is_trending_category  sl__Spring   \n",
       "131103      6.908755      0.172719                 False           1  \\\n",
       "249157     11.289794      0.128293                 False           1   \n",
       "107410      3.044522      0.338280                 False           1   \n",
       "251783      4.605170      0.057565                 False           1   \n",
       "95067       7.550135      0.260349                 False           1   \n",
       "\n",
       "        sl__Summer  sl__Winter  sd__Spring  sd__Summer  sd__Winter   \n",
       "131103           0           0           1           0           0  \\\n",
       "249157           0           0           0           1           0   \n",
       "107410           0           0           1           0           0   \n",
       "251783           0           0           0           1           0   \n",
       "95067            0           0           1           0           0   \n",
       "\n",
       "        cat__Creative  cat__Entertainment  cat__Other  cat__Tech  co__Europe   \n",
       "131103              0                   0           0          0           0  \\\n",
       "249157              0                   1           0          0           0   \n",
       "107410              1                   0           0          0           0   \n",
       "251783              0                   0           0          1           0   \n",
       "95067               0                   0           0          0           0   \n",
       "\n",
       "        co__North America  co__Oceania  \n",
       "131103                  1            0  \n",
       "249157                  1            0  \n",
       "107410                  1            0  \n",
       "251783                  1            0  \n",
       "95067                   1            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test split head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>duration_days</th>\n",
       "      <th>goal_per_category</th>\n",
       "      <th>launched_weekday</th>\n",
       "      <th>log_usd_goal</th>\n",
       "      <th>goal_per_day</th>\n",
       "      <th>is_trending_category</th>\n",
       "      <th>sl__Spring</th>\n",
       "      <th>sl__Summer</th>\n",
       "      <th>sl__Winter</th>\n",
       "      <th>sd__Spring</th>\n",
       "      <th>sd__Summer</th>\n",
       "      <th>sd__Winter</th>\n",
       "      <th>cat__Creative</th>\n",
       "      <th>cat__Entertainment</th>\n",
       "      <th>cat__Other</th>\n",
       "      <th>cat__Tech</th>\n",
       "      <th>co__Europe</th>\n",
       "      <th>co__North America</th>\n",
       "      <th>co__Oceania</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150884</th>\n",
       "      <td>-0.020717</td>\n",
       "      <td>0.813948</td>\n",
       "      <td>0.183903</td>\n",
       "      <td>4</td>\n",
       "      <td>9.575405</td>\n",
       "      <td>0.212787</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60248</th>\n",
       "      <td>-0.014269</td>\n",
       "      <td>-0.341176</td>\n",
       "      <td>-0.834371</td>\n",
       "      <td>4</td>\n",
       "      <td>9.903538</td>\n",
       "      <td>0.330118</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81434</th>\n",
       "      <td>-0.036741</td>\n",
       "      <td>0.813948</td>\n",
       "      <td>2.487783</td>\n",
       "      <td>4</td>\n",
       "      <td>6.216606</td>\n",
       "      <td>0.138147</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196247</th>\n",
       "      <td>-0.008507</td>\n",
       "      <td>1.969073</td>\n",
       "      <td>1.515510</td>\n",
       "      <td>4</td>\n",
       "      <td>10.126671</td>\n",
       "      <td>0.168778</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261828</th>\n",
       "      <td>-0.036500</td>\n",
       "      <td>1.275998</td>\n",
       "      <td>2.487783</td>\n",
       "      <td>4</td>\n",
       "      <td>6.565152</td>\n",
       "      <td>0.128728</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        usd_goal_real  duration_days  goal_per_category  launched_weekday   \n",
       "150884      -0.020717       0.813948           0.183903                 4  \\\n",
       "60248       -0.014269      -0.341176          -0.834371                 4   \n",
       "81434       -0.036741       0.813948           2.487783                 4   \n",
       "196247      -0.008507       1.969073           1.515510                 4   \n",
       "261828      -0.036500       1.275998           2.487783                 4   \n",
       "\n",
       "        log_usd_goal  goal_per_day  is_trending_category  sl__Spring   \n",
       "150884      9.575405      0.212787                 False           0  \\\n",
       "60248       9.903538      0.330118                 False           0   \n",
       "81434       6.216606      0.138147                 False           0   \n",
       "196247     10.126671      0.168778                 False           0   \n",
       "261828      6.565152      0.128728                 False           0   \n",
       "\n",
       "        sl__Summer  sl__Winter  sd__Spring  sd__Summer  sd__Winter   \n",
       "150884           0           0           0           0           1  \\\n",
       "60248            0           0           0           0           1   \n",
       "81434            0           0           0           0           1   \n",
       "196247           0           0           0           0           1   \n",
       "261828           0           0           0           0           1   \n",
       "\n",
       "        cat__Creative  cat__Entertainment  cat__Other  cat__Tech  co__Europe   \n",
       "150884              0                   1           0          0           0  \\\n",
       "60248               1                   0           0          0           0   \n",
       "81434               0                   0           0          1           0   \n",
       "196247              0                   0           1          0           0   \n",
       "261828              0                   0           0          1           0   \n",
       "\n",
       "        co__North America  co__Oceania  \n",
       "150884                  1            0  \n",
       "60248                   1            0  \n",
       "81434                   1            0  \n",
       "196247                  1            0  \n",
       "261828                  1            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# put it back together again \n",
    "X_train_sp = pd.concat([X_train_scaled, X_train ], axis=1)\n",
    "X_test_sp = pd.concat([X_test_scaled, X_test], axis=1)\n",
    "#and check\n",
    "print(\"Dff shape\", dff.shape)\n",
    "print(\"X_train shape\", X_train_scaled.shape)\n",
    "print(\"X_test shape\", X_test_scaled.shape)\n",
    "print(\"X_train shape after scaling\", X_train_sp.shape)\n",
    "print(\"X_test shape after scaling\", X_test_sp.shape)\n",
    "print(\"train split head:\")\n",
    "display(X_train_sp.head())\n",
    "print(\"test split head:\")\n",
    "display(X_test_sp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Ensemble Method: Weighed Averages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "##### current feature engineering (CHANGE ME)\n",
    "\n",
    "you can start using the train-test-split: \n",
    "* X_train_sp\n",
    "* X_test_sp\n",
    "* y_train\n",
    "* y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Final Features (CHANGE ME)\n",
    "| Column | Data | Decision | Done |\n",
    "|:--------:|:--------:|:--------:|:--------:|\n",
    "|  Category  |  >150 Subcategories   |  included in main category   | ignore |\n",
    "|main_category| 15 categories| checked, makes a difference| use but make even less granular|\n",
    "|Topic|4 clusters: Tech, Entertaiment, Creative, Other||\n",
    "|country|country of project|informative, but too many|reduced to continents|\n",
    "|usd_pledged_real|redundant apparently|same as pledged | ignored|\n",
    "|deadline| unclear! probably stated end date of kickstarter| used |ignored|\n",
    "|state|used as target |removed all but \"success and fail\"|keep and create new column with numerical values|\n",
    "|country|country of project|informative, but too many|reduced to continents|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Weighed Average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programming\\ai_ds_bootcamp\\ds-ml-project_kickstarters\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63710099\n",
      "F1 Score: 0.63721475\n"
     ]
    }
   ],
   "source": [
    "#first, get our three models \n",
    "model1 = LogisticRegression(C = 0.01, solver= 'lbfgs', random_state = 42)\n",
    "model2 = KNeighborsClassifier(n_neighbors=21, algorithm='auto', metric='minkowski', p=1, weights='uniform')\n",
    "model3 = DecisionTreeClassifier(max_depth=3, min_samples_leaf = 1,  min_samples_split = 2, random_state = 42)\n",
    "#model4 = \n",
    "\n",
    "#fit them individually \n",
    "model1.fit(X_train_sp,y_train)\n",
    "model2.fit(X_train_sp,y_train)\n",
    "model3.fit(X_train_sp,y_train)\n",
    "#get individual predictions \n",
    "pred1 = model1.predict_proba(X_test_sp)\n",
    "pred2 = model2.predict_proba(X_test_sp)\n",
    "pred3 = model3.predict_proba(X_test_sp)\n",
    "#returns array len(X_test) with predicted probability for pos / neg values \n",
    "#---- score it: \n",
    "#f1_1 = f1_score(y_test, pred1, average='weighted')\n",
    "\n",
    "acc1 = accuracy_score(y_train, model1.predict(X_train_sp))\n",
    "acc2 = accuracy_score(y_train, model2.predict(X_train_sp))\n",
    "acc3 = accuracy_score(y_train, model3.predict(X_train_sp))\n",
    "#sum it up: \n",
    "acc_sum = acc1 + acc2 + acc3\n",
    "# now it gets interesting: \n",
    "weight1 = acc1/acc_sum #which proportion of the outcome\n",
    "weight2 = acc2/acc_sum #does each prediction\n",
    "weight3 = acc3/acc_sum #actually have?\n",
    "#then use those weights on the predictions to go for it: \n",
    "finalpred = (pred1*weight1 + pred2*weight2 + pred3*weight3)\n",
    "#and max that again - as it's an array\n",
    "finalpred = np.argmax(finalpred.round(0), axis=1)\n",
    "print(f\"Accuracy: {(y_test == finalpred).sum() / len(finalpred):.8f}\")\n",
    "\n",
    "\n",
    "# F! Score:\n",
    "\n",
    "f1_1 = f1_score(y_train, model1.predict(X_train_sp), average='weighted')\n",
    "f1_2 = f1_score(y_train, model2.predict(X_train_sp), average='weighted')\n",
    "f1_3 = f1_score(y_train, model3.predict(X_train_sp), average='weighted')\n",
    "#sum it up: \n",
    "f1n_sum = f1_1 + f1_2 + f1_3\n",
    "# now it gets interesting: \n",
    "weight1 = f1_1/f1n_sum #which proportion of the outcome\n",
    "weight2 = f1_2/f1n_sum #does each prediction\n",
    "weight3 = f1_3/f1n_sum #actually have?\n",
    "#then use those weights on the predictions to go for it: \n",
    "finalpred = (pred1*weight1 + pred2*weight2 + pred3*weight3)\n",
    "#and max that again - as it's an array\n",
    "finalpred = np.argmax(finalpred.round(0), axis=1)\n",
    "print(f\"F1 Score: {(y_test == finalpred).sum() / len(finalpred):.8f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
