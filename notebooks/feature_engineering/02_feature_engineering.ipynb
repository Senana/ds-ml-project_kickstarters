{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial imports \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Get the absolute path of the current file/notebook\n",
    "# If using Jupyter, use Path.cwd(). If using a .py script, use Path(__file__).parent\n",
    "curr_dir = Path.cwd()\n",
    "\n",
    "# Calculate the project root (adjust '.parent' count as needed)\n",
    "# If your notebook is in 'project/notebooks/', the root is 1 level up\n",
    "project_root = curr_dir.parent.parent \n",
    "\n",
    "# Add project root to system path so Python can find 'utils'\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project Root added to path: {project_root}\")\n",
    "\n",
    "from utils.feature_engineer_df import build_features \n",
    "\n",
    "#for the scaling and encoding \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#cleanup \n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_features(\n",
    "    input_path=Path.cwd().resolve().parents[1] / \"data\" / \"cleaned\" / \"kickstarter_cleaned.csv\",\n",
    "    output_path=Path.cwd().resolve().parents[1] / \"data\" / \"feature\" / \"kickstarter_featured.csv\",\n",
    "    raw_path=Path.cwd().resolve().parents[1] / \"data\" / \"raw\" / \"ks-projects-201801.csv\",\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Load Files as DataFrames\n",
    "BASE_DIR = Path.cwd().resolve().parents[1]\n",
    "data_file = BASE_DIR / \"data\" / \"feature\" / \"kickstarter_featured.csv\"\n",
    "\n",
    "filepath = Path(data_file)\n",
    "\n",
    "df = pd.read_csv(filepath, encoding='latin-1', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Creating our feature engineering dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns to \"hard drop\" from feature engineering dataframe\n",
    "columns_to_drop = ['id', #irrelevant\n",
    "                   'main_category', #substituted in a satisfactory way\n",
    "                   'deadline', 'launched', #created new categories \n",
    "                   'backers', 'usd_pledged_real', 'usd_pledged_bins', 'backers_per_pledged', 'backer_pledged_bins', 'pledged_per_category', #everything to do with \"future information\"\n",
    "                   'launched_year', 'deadline_year', #info about the past and not seasonal\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remember: These would need to be soft-dropped later \n",
    "# columns_to_softdrop = ['country', #to play around with\n",
    "#                        'duration_days', #because the bins are not ideal\n",
    "#                        'launched_month', 'deadline_month', #because we have season but might want to look closer\n",
    "#                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df.drop(columns=columns_to_drop)\n",
    "dfc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Prepare categorical features for machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We want to get dummies for all categoricals, that is \n",
    "* season_launched, season_deadline\n",
    "* main_category_grouped\n",
    "* continent\n",
    "\n",
    "Open question: Scale or do dummies? \n",
    "* category_goal_percentile (as it's ordinal)\n",
    "* duration bins (ordinal as well)\n",
    "\n",
    "Scale:  \n",
    "* usd_goal_real\n",
    "* goal_per_category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Get dummies:\n",
    "\n",
    "#question: how do we later know the legend? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#season launched, dropping first as it's multicollinear\n",
    "df_sl = pd.get_dummies(df['launch_season'], prefix = 'sl_', drop_first=True, dtype=int)\n",
    "\n",
    "#season deadline, dropping first\n",
    "df_sd = pd.get_dummies(df['deadline_season'], prefix = 'sd_', drop_first=True, dtype=int)\n",
    "\n",
    "#main category_grouped, dropping first\n",
    "df_cat = pd.get_dummies(df['main_category_grouped'], prefix = 'cat_', drop_first=True, dtype=int)\n",
    "\n",
    "#continent, dropping first\n",
    "df_co = pd.get_dummies(df['continent'], prefix = 'co_', drop_first=True, dtype=int)\n",
    "\n",
    "#put everything back together again: \n",
    "dff = pd.concat([dfc, df_sl, df_sd, df_cat, df_co], axis=1)\n",
    "\n",
    "#check if it worked\n",
    "display(dff.head()) \n",
    "#check for errors in creation \n",
    "display(dff.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Tried to use ordinal encoder, the results don't look right. Dropped it for now. \n",
    "\n",
    "#use ordinal encoder for the ordinal categories \n",
    "encoder = OrdinalEncoder()\n",
    "#make categories numerical \n",
    "#ordinal_encod_map = {'Very Low': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very High': 4}\n",
    "#dff['category_goal_percentile'] = dff['category_goal_percentile'].map(ordinal_encod_map)\n",
    "df['duration_bins_coded'] = encoder.fit_transform(df[['duration_bins']])\n",
    "df[['duration_bins', 'duration_bins_coded']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's soft-drop everything we just encoded\n",
    "#commented out all the keepers \n",
    "columns_to_softdrop = ['country', #we kept it for comparison\n",
    "                       # 'usd_goal_real', #right now I want to try scaling actual values \n",
    "                       #'duration_days', #I want to scale these and drop the bins instead for now \n",
    "                       # 'target', (obviously)\n",
    "                       'main_category_grouped', 'continent', #after creating dummies, get rid of these!\n",
    "                        'launched_month', 'deadline_month', #because we have season but might want to look closer\n",
    "                        'usd_goal_bins', #using category_goal_percentile (those two are redundant)\n",
    "                        #'goal_per_category', #it's a polynomial feature - not independent but that's probably ok\n",
    "                       'category_goal_percentile', #it's an orinal bin so keeping 'goal per category' instead\n",
    "                       'duration_bins', #want to use actual values instead, using duration_days\n",
    "                       'launch_season', 'deadline_season', #gotten dummies \n",
    "                       #'duration_bins_coded', #dropped the whole encoding code \n",
    "                       ]\n",
    "# keeping the already dummied ones obviously \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_scale = dff.drop(columns=columns_to_softdrop, axis=1)\n",
    "display(df_to_scale.columns)\n",
    "display(df_to_scale.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Let's try at least two ways of doing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, create our dfs \n",
    "X = df_to_scale.drop(columns=['target'])\n",
    "y = df_to_scale['target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)\n",
    "print(\"Df before\", df_to_scale.shape)\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's standardise first: \n",
    "col_scale = ['usd_goal_real',\n",
    "             'duration_days',\n",
    "             'goal_per_category',\n",
    "             ]\n",
    "\n",
    "#instantiate\n",
    "scaler = StandardScaler()\n",
    "#scale \n",
    "X_train_scaled = scaler.fit_transform(X_train[col_scale])\n",
    "X_test_scaled = scaler.fit_transform(X_test[col_scale])\n",
    "#make it a df again\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    X_train_scaled,\n",
    "    columns=col_scale,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    X_test_scaled,\n",
    "    columns=col_scale,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "display(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the original axes again\n",
    "X_train = X_train.drop(col_scale, axis=1)\n",
    "X_test = X_test.drop(col_scale, axis=1)\n",
    "#and check if everything's still in order \n",
    "X_train.index.equals(X_train_scaled.index)\n",
    "X_test.index.equals(X_test_scaled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it back together again \n",
    "X_train_sp = pd.concat([X_train_scaled, X_train ], axis=1)\n",
    "X_test_sp = pd.concat([X_test_scaled, X_test], axis=1)\n",
    "#and check\n",
    "print(\"Dff shape\", dff.shape)\n",
    "print(\"X_train shape\", X_train_scaled.shape)\n",
    "print(\"X_test shape\", X_test_scaled.shape)\n",
    "print(\"X_train shape after scaling\", X_train_sp.shape)\n",
    "print(\"X_test shape after scaling\", X_test_sp.shape)\n",
    "print(\"train split head:\")\n",
    "display(X_train_sp.head())\n",
    "print(\"test split head:\")\n",
    "display(X_test_sp.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
