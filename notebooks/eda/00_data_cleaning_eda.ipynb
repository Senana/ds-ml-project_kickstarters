{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Kickstarter Dataset\n",
    "\n",
    "This notebook performs initial data cleaning on the Kickstarter dataset (df2).\n",
    "\n",
    "**Steps:**\n",
    "1. Load raw data\n",
    "2. Drop unnecessary columns\n",
    "3. Filter target states\n",
    "4. Save cleaned datasets\n",
    "\n",
    "**Outputs:**\n",
    "- `kickstarter_cleaned.csv` - only \"successful\" and \"failed\"\n",
    "- `kickstarter_cleaned_with_cancelled.csv` - includes \"cancelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path.cwd().resolve().parents[1]\n",
    "RAW_PATH = BASE_DIR / \"data\" / \"raw\"\n",
    "CLEANED_PATH = BASE_DIR / \"data\" / \"cleaned\"\n",
    "\n",
    "RAW_DATA_PATH = Path(RAW_PATH)\n",
    "CLEANED_DATA_PATH = Path(CLEANED_PATH)\n",
    "\n",
    "# Create output directory if not exists\n",
    "CLEANED_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We checked both datasets from 2016 and 2018. \n",
    "* There is considerable overlap but no discernable differences \n",
    "* 2018 contains more data\n",
    "\n",
    "We decided to use only the 2018 dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 378,661 rows, 15 columns\n",
      "\n",
      "Columns: ['ID', 'name', 'category', 'main_category', 'currency', 'deadline', 'goal', 'launched', 'pledged', 'state', 'backers', 'country', 'usd pledged', 'usd_pledged_real', 'usd_goal_real']\n"
     ]
    }
   ],
   "source": [
    "# Load df2 (the larger/newer dataset)\n",
    "# Adjust filename as needed\n",
    "df = pd.read_csv(RAW_DATA_PATH / 'ks-projects-201801.csv')\n",
    "\n",
    "print(f\"Loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Columns | Meaning | \n",
    "|:--------:|:--------:|\n",
    "|  ID  |  Unique identifier   |  \n",
    "|  name   |  Project title  | \n",
    "|  category |  Sub-category  |  \n",
    "| main_category |  Main category |\n",
    "|  currency |  Currency used for the project  | \n",
    "|  deadline |  Last day project backers can contribute | \n",
    "|  goal |  Target amount of money to be raised   | \n",
    "|  launched |  Project launch date  | \n",
    "|  pledged |  Amount of money people initially pledged  | \n",
    "|  state |  Project status (successful, canceled, failed, etc.)  | \n",
    "|  backers |  Number of people who supported the project  | \n",
    "|  country |  Country of the project creator   | \n",
    "|  usd pledged |  The 'pledged' column converted to USD (with missing data)  | \n",
    "|  usd_pledged_real |  Actual amount of money raised in USD  | \n",
    "|  usd_goal_real |  The 'goal' column converted to USD  | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 378661 entries, 0 to 378660\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ID                378661 non-null  int64  \n",
      " 1   name              378657 non-null  object \n",
      " 2   category          378661 non-null  object \n",
      " 3   main_category     378661 non-null  object \n",
      " 4   currency          378661 non-null  object \n",
      " 5   deadline          378661 non-null  object \n",
      " 6   goal              378661 non-null  float64\n",
      " 7   launched          378661 non-null  object \n",
      " 8   pledged           378661 non-null  float64\n",
      " 9   state             378661 non-null  object \n",
      " 10  backers           378661 non-null  int64  \n",
      " 11  country           378661 non-null  object \n",
      " 12  usd pledged       374864 non-null  float64\n",
      " 13  usd_pledged_real  378661 non-null  float64\n",
      " 14  usd_goal_real     378661 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(8)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Quick overview\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State distribution (before):\n",
      "state\n",
      "failed        197719\n",
      "successful    133956\n",
      "canceled       38779\n",
      "undefined       3562\n",
      "live            2799\n",
      "suspended       1846\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total: 378,661\n"
     ]
    }
   ],
   "source": [
    "# Check state distribution before cleaning\n",
    "print(\"State distribution (before):\")\n",
    "print(df['state'].value_counts())\n",
    "print(f\"\\nTotal: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the consolidated dataset, we do the initial cleaning of code. We drop the most obvious candidates which won't help the upcoming analysis.\n",
    "\n",
    "The rest is refined iteratively later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Unnecessary Columns\n",
    "\n",
    "**Dropping:**\n",
    "- `name` - text, not needed for initial model\n",
    "- `category` - too granular, keeping `main_category`\n",
    "- `goal` - keeping `usd_goal_real` (normalized)\n",
    "- `pledged` - keeping `usd_pledged_real` (normalized)\n",
    "- `currency` - not needed since we use USD columns\n",
    "- `usd pledged` - Kickstarter's conversion, less accurate than `usd_pledged_real`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning: \n",
    "* we won't be able to work with the names (yet)\n",
    "* we will only work with the main_category as it's less granular and sufficient \n",
    "* Goal, pledged and currency go together, we work only with usd for reasons of comparison\n",
    "* usd_pledged seems redundant so we leave it out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will drop: ['name', 'category', 'goal', 'pledged', 'currency', 'usd pledged']\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop\n",
    "COLS_TO_DROP = [\n",
    "    'name',\n",
    "    'category',\n",
    "    'goal',\n",
    "    'pledged',\n",
    "    'currency',\n",
    "    'usd pledged',\n",
    "]\n",
    "\n",
    "# Check which columns exist before dropping\n",
    "existing_to_drop = [col for col in COLS_TO_DROP if col in df.columns]\n",
    "missing = [col for col in COLS_TO_DROP if col not in df.columns]\n",
    "\n",
    "print(f\"Will drop: {existing_to_drop}\")\n",
    "if missing:\n",
    "    print(f\"Not found (skipping): {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before: 15\n",
      "Columns after: 9\n",
      "\n",
      "Remaining columns: ['ID', 'main_category', 'deadline', 'launched', 'state', 'backers', 'country', 'usd_pledged_real', 'usd_goal_real']\n"
     ]
    }
   ],
   "source": [
    "# Drop columns\n",
    "df_clean = df.drop(columns=existing_to_drop)\n",
    "\n",
    "print(f\"Columns before: {len(df.columns)}\")\n",
    "print(f\"Columns after: {len(df_clean.columns)}\")\n",
    "print(f\"\\nRemaining columns: {df_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to use durations and manipulate dates, so we transform the strings into regular datetime-columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dates into datetime\n",
    "# deadline, launched - should be datetime types\n",
    "df_clean[\"launched\"] = pd.to_datetime(df_clean[\"launched\"], errors=\"coerce\")\n",
    "df_clean[\"deadline\"] = pd.to_datetime(df_clean[\"deadline\"], errors=\"coerce\")\n",
    "\n",
    "# create new column - duration_days\n",
    "df_clean[\"duration_days\"] = (\n",
    "    df_clean[\"deadline\"] - df_clean[\"launched\"]\n",
    ").dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of use, we transform the category names to have homogenous formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Renamed columns: ['id', 'main_category', 'deadline', 'launched', 'state', 'backers', 'country', 'usd_pledged_real', 'usd_goal_real', 'duration_days']\n"
     ]
    }
   ],
   "source": [
    "# Columns clear naming\n",
    "df_clean.columns = df_clean.columns.str.strip().str.replace(' ', '_').str.lower()\n",
    "print(f\"\\nRenamed columns: {df_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Target States\n",
    "\n",
    "**Keeping:**\n",
    "- `successful` ✅\n",
    "- `failed` ✅\n",
    "- `canceled` (optional dataset)\n",
    "\n",
    "**Dropping:**\n",
    "- `live` - still running\n",
    "- `suspended` - removed by Kickstarter\n",
    "- `undefined` - unknown state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning: \n",
    "* There are only a few projects in \"undefined\" state. \n",
    "* For prediction reasons, those don't provide additional information as they are neither failed nor sucessful\n",
    "* We are considering keeping \"cancelled\" as it's a type of failed \n",
    "* It would be fair to drop \"cancelled\" as it's self-initiated and constitutes a different set of probabilities than \"failed for external reasons\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second half, we initially kept two datasets with \"cancelled\" and without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state distribution:\n",
      "state\n",
      "failed        197719\n",
      "successful    133956\n",
      "canceled       38779\n",
      "undefined       3562\n",
      "live            2799\n",
      "suspended       1846\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define states\n",
    "MAIN_STATES = ['successful', 'failed']\n",
    "OPTIONAL_STATE = 'canceled'\n",
    "\n",
    "# Check current distribution\n",
    "print(\"Current state distribution:\")\n",
    "print(df_clean['state'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main dataset (successful + failed):\n",
      "  Rows: 331,675\n",
      "  Distribution:\n",
      "state\n",
      "failed        197719\n",
      "successful    133956\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dataset 1: Only successful & failed\n",
    "df_main = df_clean[df_clean['state'].isin(MAIN_STATES)].copy()\n",
    "\n",
    "print(f\"Main dataset (successful + failed):\")\n",
    "print(f\"  Rows: {len(df_main):,}\")\n",
    "print(f\"  Distribution:\")\n",
    "print(df_main['state'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with cancelled:\n",
      "  Rows: 370,454\n",
      "  Distribution:\n",
      "state\n",
      "failed        197719\n",
      "successful    133956\n",
      "canceled       38779\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dataset 2: Including cancelled\n",
    "states_with_cancelled = MAIN_STATES + [OPTIONAL_STATE]\n",
    "df_with_cancelled = df_clean[df_clean['state'].isin(states_with_cancelled)].copy()\n",
    "\n",
    "print(f\"Dataset with cancelled:\")\n",
    "print(f\"  Rows: {len(df_with_cancelled):,}\")\n",
    "print(f\"  Distribution:\")\n",
    "print(df_with_cancelled['state'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main dataset target distribution:\n",
      "target\n",
      "0    197719\n",
      "1    133956\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For main dataset: successful=1, failed=0\n",
    "df_main['target'] = (df_main['state'] == 'successful').astype(int)\n",
    "\n",
    "# Drop state columns\n",
    "df_main = df_main.drop(columns=['state'])\n",
    "\n",
    "print(\"Main dataset target distribution:\")\n",
    "print(df_main['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with cancelled - target distribution:\n",
      "target\n",
      "0    236498\n",
      "1    133956\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For dataset with cancelled: successful=1, failed/canceled=0\n",
    "df_with_cancelled['target'] = (df_with_cancelled['state'] == 'successful').astype(int)\n",
    "\n",
    "\n",
    "# Drop state columns\n",
    "df_with_cancelled = df_with_cancelled.drop(columns=['state'])\n",
    "\n",
    "print(\"Dataset with cancelled - target distribution:\")\n",
    "print(df_with_cancelled['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Cleaned Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data can be imported regularly into further notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: D:\\Programming\\ai_ds_bootcamp\\ds-ml-project_kickstarters\\data\\cleaned\\kickstarter_cleaned.csv\n",
      "\n",
      " Saved: D:\\Programming\\ai_ds_bootcamp\\ds-ml-project_kickstarters\\data\\cleaned\\kickstarter_cleaned_with_cancelled.csv\n"
     ]
    }
   ],
   "source": [
    "# Save main dataset\n",
    "main_path = CLEANED_DATA_PATH / 'kickstarter_cleaned.csv'\n",
    "df_main.to_csv(main_path, index=False)\n",
    "print(f\" Saved: {main_path}\")\n",
    "\n",
    "# Save dataset with cancelled\n",
    "cancelled_path = CLEANED_DATA_PATH / 'kickstarter_cleaned_with_cancelled.csv'\n",
    "df_with_cancelled.to_csv(cancelled_path, index=False)\n",
    "print(f\"\\n Saved: {cancelled_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA CLEANING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Original dataset:\n",
      "  - Rows: 378,661\n",
      "  - Columns: 15\n",
      "\n",
      "Dropped columns:\n",
      "  - ['name', 'category', 'goal', 'pledged', 'currency', 'usd pledged']\n",
      "\n",
      "Main dataset (kickstarter_cleaned.csv):\n",
      "  - States: successful, failed\n",
      "  - Rows: 331,675\n",
      "\n",
      "With cancelled (kickstarter_cleaned_with_cancelled.csv):\n",
      "  - States: successful, failed, canceled\n",
      "  - Rows: 370,454\n",
      "\n",
      "Output location: D:\\Programming\\ai_ds_bootcamp\\ds-ml-project_kickstarters\\data\\cleaned\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATA CLEANING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "Original dataset:\n",
    "  - Rows: {len(df):,}\n",
    "  - Columns: {len(df.columns)}\n",
    "\n",
    "Dropped columns:\n",
    "  - {existing_to_drop}\n",
    "\n",
    "Main dataset (kickstarter_cleaned.csv):\n",
    "  - States: successful, failed\n",
    "  - Rows: {len(df_main):,}\n",
    "\n",
    "With cancelled (kickstarter_cleaned_with_cancelled.csv):\n",
    "  - States: successful, failed, canceled\n",
    "  - Rows: {len(df_with_cancelled):,}\n",
    "\n",
    "Output location: {CLEANED_DATA_PATH.absolute()}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
